{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c16328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d35338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo Tensor\n",
    "# Từ mảng \n",
    "data = [[1,2], [3,4]]\n",
    "# Từ numpy array\n",
    "data = np.array(([1,2], [3,4]), dtype=float)\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "print()\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6128df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thông số của Tensor\n",
    "tensor = torch.rand((3,4))\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5250713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phép toán với Tensor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tensor = tensor.to(device)\n",
    "print(tensor.device)\n",
    "\n",
    "# Chuyển từ numpy sang torch\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "# Chuyển từ torch sang numpy\n",
    "\n",
    "t = torch.ones(5)\n",
    "n = t.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60bbdf9",
   "metadata": {},
   "source": [
    "# torch.autograd\n",
    "\n",
    "Mạng NN là tập hợp các hàm lồng nhau để thực thi 1 tập input\n",
    "Các hàm này được xác định bởi weights và bias - trọng số\n",
    "Các trọng số được lưu dứoi dạng Tensor\n",
    "\n",
    "Forward: Dự đoán kết quả đầu ra. Input -> L1 -> ... -> Output\n",
    "\n",
    "Backward: Điều chỉnh trọng số ứng với sai số trong dự đoán\n",
    "Duyệt ngược từ đầu ra, thu thập đạo hàm của sai số theo gradient, tối ưu hoá bằng giảm gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 18),\n",
    "    nn.Linear(18, 20),\n",
    "    nn.Linear(20, 5),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "a = torch.rand(10).reshape(-1,10)\n",
    "output = model(a)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82d0ec",
   "metadata": {},
   "source": [
    "# Các bài toán phân loại đơn giản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification\n",
    "\n",
    "input_data = torch.tensor(\n",
    "    np.random.rand(5,6), dtype= torch.float\n",
    ")\n",
    "print(f'input data: ', input_data)\n",
    "print()\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(f'output: ', output)\n",
    "# five probs [0, 1] for 5 animals\n",
    "# class = 1 mammals, class = 0 not mammals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-class classification\n",
    "\n",
    "n_classes = 3\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,n_classes),\n",
    "    nn.Softmax(-1)\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(f'output: ', [torch.argmax(i) for i in output])\n",
    "print(f'output: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 4), # First linear layer\n",
    "    nn.Linear(4, 1) # Second linear layer\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d0076",
   "metadata": {},
   "source": [
    "# Sử dụng Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # CrossEntropyLoss\n",
    "\n",
    "loss = CrossEntropyLoss(output, input_data)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415a1df",
   "metadata": {},
   "source": [
    "# Lan truyền ngược"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d238224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Perform parameters updates\n",
    "\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894458fc",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb79ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.uniform(low=0, high=2, size=(5,5)).astype(int)\n",
    "X1 = (np.random.uniform(low=1,high=3,size=(5,1))).astype(int) * 2\n",
    "X2 = np.random.uniform(low=0, high=2, size=(5,2)).astype(int)\n",
    "\n",
    "X = np.concatenate((X,X1), axis=1)\n",
    "X = np.concatenate((X,X2), axis=1)\n",
    "print(X)\n",
    "\n",
    "Y = [0, 0, 1, 1, 2]\n",
    "print(Y)\n",
    "\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(X), torch.tensor(Y))\n",
    "input_sample, label_sample = dataset[0]\n",
    "print(f'input_sample: ', input_sample)\n",
    "print(f'label_sample: ', label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66916c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,shuffle=shuffle)\n",
    "\n",
    "for batch_inputs, batch_labels in dataloader:\n",
    "    print(f'batch_inputs: ', batch_inputs)\n",
    "    print(f'batch_lables: ', batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc05ad1",
   "metadata": {},
   "source": [
    "# Khởi tạo Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b320a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo Layer bình thường\n",
    "layer = nn.Linear(64,128)\n",
    "print(layer.weight.min(), layer.weight.max())\n",
    "\n",
    "# Khởi tạo Layer uniform\n",
    "layer = nn.Linear(64,128)\n",
    "nn.init.uniform_(layer.weight)\n",
    "\n",
    "print(layer.weight.min(), layer.weight.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14a023",
   "metadata": {},
   "source": [
    "# Reuser Model đã học"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(5,12)\n",
    "# Lưu weight\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Tạo cái vỏ mới\n",
    "new_model = nn.Linear(5,12)\n",
    "# Load weight\n",
    "new_model.load_state_dict(torch.load('model.pth', weights_only=True))\n",
    "\n",
    "print(torch.equal(new_model.weight, model.weight))\n",
    "print(torch.equal(new_model.bias, model.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494087d1",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "- Learning rate nhỏ\n",
    "- Đóng băng 1 vài layer\n",
    "- Đóng bằng layer gần input và fine-tune layer gần output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25332cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(5, 10),\n",
    "        nn.Linear(10, 5))\n",
    "\n",
    "# Freeze weight layer 1\n",
    "for name, param in model.named_parameters():\n",
    "    if name == '0.weight':\n",
    "        param.requires_grad = False\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Freeze layer 1\n",
    "for param in model[0].parameters():\n",
    "    param.requires_grad = False\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "365ecdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(8 ,1))\n",
    "print(model[0].weight.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e23a6d",
   "metadata": {},
   "source": [
    "# Train 1 mạng NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fr'data_science_salaries.csv')\n",
    "data = df[['experience_level', 'employment_type', 'work_models', 'company_size', 'salary_in_usd']]\n",
    "# print(data)\n",
    "print(df['experience_level'].value_counts())\n",
    "print()\n",
    "print(df['employment_type'].value_counts())\n",
    "print()\n",
    "print(df['work_models'].value_counts())\n",
    "print()\n",
    "print(df['company_size'].value_counts())\n",
    "print()\n",
    "print(df['salary_in_usd'].dtype)\n",
    "# Convert to number\n",
    "experience_map = {\n",
    "    'Entry-level': 0,\n",
    "    'Mid-level': 1,\n",
    "    'Senior-level': 2,\n",
    "    'Executive-level': 3\n",
    "}\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_map)\n",
    "\n",
    "employment_map = {\n",
    "    'Full-time': 0,\n",
    "    'Contract': 1,\n",
    "    'Part-time': 2,\n",
    "    'Freelance': 3\n",
    "}\n",
    "df['employment_type_encoded'] = df['employment_type'].map(employment_map)\n",
    "\n",
    "size_map = {\n",
    "    'Small': 0,\n",
    "    'Medium': 1,\n",
    "    'Large': 2\n",
    "}\n",
    "df['company_size_encoded'] = df['company_size'].map(size_map)\n",
    "\n",
    "work_model_map = {\n",
    "    'On-site': 0,\n",
    "    'Remote': 1,\n",
    "    'Hybrid': 2\n",
    "}\n",
    "\n",
    "df['work_models_encoded'] = df['work_models'].map(work_model_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['experience_level_encoded', 'employment_type_encoded', 'work_models_encoded', 'company_size_encoded', 'salary_in_usd']]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b770e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['salary_in_usd'] )\n",
    "target = df['salary_in_usd']\n",
    "\n",
    "print(\"=== DỮ LIỆU TRƯỚC KHI CHUẨN HÓA ===\")\n",
    "print(f\"Target - Min: {target.min()}, Max: {target.max()}\")\n",
    "print(f\"Target - Mean: {target.mean():.2f}, Std: {target.std():.2f}\")\n",
    "\n",
    "# Chuẩn hoá Z - SCORE THỦ CÔNG\n",
    "target_mean = target.mean()\n",
    "target_std = target.std()\n",
    "\n",
    "target_zscore = (target - target_mean) / target_std\n",
    "\n",
    "\n",
    "print(\"=== DỮ LIỆU SAU KHI CHUẨN HÓA ===\")\n",
    "print(f\"Target - Min: {target_zscore.min()}, Max: {target_zscore.max()}\")\n",
    "print(f\"Target - Mean: {target_zscore.mean():.2f}, Std: {target_zscore.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5720cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 8/10\n",
    "\n",
    "train_sample = 6599 * rate\n",
    "train_sample = int(train_sample)\n",
    "\n",
    "train_features = df[['experience_level_encoded', 'employment_type_encoded', 'work_models_encoded', 'company_size_encoded']].iloc[:train_sample]\n",
    "train_target = target_zscore.iloc[:train_sample]\n",
    "\n",
    "test_features = df[['experience_level_encoded', 'employment_type_encoded', 'work_models_encoded', 'company_size_encoded']].iloc[train_sample:]\n",
    "test_target = target_zscore.iloc[train_sample:]\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_features.values).float(),\n",
    "                        torch.tensor(train_target.values).float())\n",
    "test_dataset = TensorDataset(torch.tensor(test_features.values).float(),\n",
    "                        torch.tensor(test_target.values).float())\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=100)\n",
    "\n",
    "# Model với initialization tốt hơn\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4,16),   # Tăng hidden size\n",
    "    nn.ReLU(),        # Thêm activation\n",
    "    nn.Linear(16,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,1)\n",
    ")\n",
    "\n",
    "# Khởi tạo weights\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)  # Giảm learning rate\n",
    "\n",
    "# Test 1 batch để xem thử dữ liệu\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "feature_sample, target_sample = sample_batch\n",
    "\n",
    "\n",
    "print(f\"\\n=== SAMPLE BATCH ===\")\n",
    "print(f\"Feature sample shape: {feature_sample.shape}\")\n",
    "print(f\"Target sample shape: {target_sample.shape}\")\n",
    "print(f\"Sample features:\\n{feature_sample[:3]}\")\n",
    "print(f\"Sample targets: {target_sample[:3]}\")\n",
    "\n",
    "# Test prediction với sample\n",
    "with torch.no_grad():\n",
    "    sample_pred = model(feature_sample[:3])\n",
    "    sample_loss = criterion(sample_pred.squeeze(), target_sample[:3])\n",
    "    print(f\"Sample prediction: {sample_pred.squeeze()}\")\n",
    "    print(f\"Sample loss: {sample_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "loss_arr = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % 10 == 0:  # Print mỗi 10 epochs để tránh spam\n",
    "        print(f\"Epoch {epoch}\")\n",
    "    for data in train_dataloader:\n",
    "        # Get features and target from the data loader\n",
    "        feature, target = data\n",
    "        # Run forward pass\n",
    "        pred = model(feature)\n",
    "        # Compute loss & gradients\n",
    "        loss = criterion(pred.squeeze(), target)\n",
    "        loss.backward()\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        # Set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_arr.append(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe008864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "windows = [50, 100, 200]\n",
    "colors = ['red', 'green', 'blue']\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 6))\n",
    "def smooth_loss(loss_arr, window):\n",
    "    \"\"\"Sử dụng pandas rolling để smooth loss\"\"\"\n",
    "    loss_series = pd.Series(loss_arr)\n",
    "    smoothed = loss_series.rolling(window=window, min_periods=1).mean()\n",
    "    return smoothed.values\n",
    "\n",
    "for i in range(len(windows)):\n",
    "    smooth_values = smooth_loss(loss_arr, window=windows[i])\n",
    "    \n",
    "    ax[i].plot(loss_arr, alpha=0.3, label='Raw Loss', color='gray')\n",
    "    ax[i].plot(smooth_values, linewidth=2, label=f'Smooth Loss (w={windows[i]})', color=colors[i])\n",
    "    \n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(f'Simple Loss Smoothing (window={windows[i]})')\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel('Loss')\n",
    "\n",
    "# Gộp lại ngoài vòng lặp\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bb78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_target(zscore_pred):\n",
    "    return zscore_pred * target_std + target_mean\n",
    "\n",
    "predictions_zscore = []\n",
    "targets_zscore = []\n",
    "\n",
    "model.eval()\n",
    "# Tắt gradients\n",
    "with torch.no_grad():\n",
    "    # Chạy forward pass\n",
    "    for features, target in test_dataloader:\n",
    "        # Chạy forward pass\n",
    "        pred_zscore = model(features)\n",
    "        predictions_zscore.extend(pred_zscore)\n",
    "        targets_zscore.extend(target)\n",
    "\n",
    "predictions_zscore = np.array(predictions_zscore)\n",
    "targets_zscore = np.array(targets_zscore)\n",
    "\n",
    "predictions_actual = denormalize_target(predictions_zscore)\n",
    "targets_actual = denormalize_target(targets_zscore)\n",
    "\n",
    "print(f\"\\n=== SO SÁNH KẾT QUẢ ===\")\n",
    "print(\"Z-score predictions:\", predictions_zscore[:7].reshape(-1))\n",
    "print(\"Z-score targets:     \", targets_zscore[:7])\n",
    "print()\n",
    "print(\"Actual predictions:  \", predictions_actual[:7].reshape(-1))\n",
    "print(\"Actual targets:      \", targets_actual[:7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
